{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import tensorflow as tf\n",
    "df = pd.read_csv(\"E:/fraud-detection/data/creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of fraud of all transactions is  0.173 %\n"
     ]
    }
   ],
   "source": [
    "fraud_ind=df[df.Class==1].index\n",
    "nofraud_ind=df[df.Class==0].index\n",
    "fraud_num=len(fraud_ind)\n",
    "nofraud_num=len(nofraud_ind)\n",
    "fraud_perc=round(fraud_num/(fraud_num+nofraud_num),5)*100\n",
    "print(\"% of fraud of all transactions is \", fraud_perc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Class\n",
    "x=df.drop(['Class','Time','Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all of the features that have very similar distributions between the two types of transactions.\n",
    "df_features=df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8','Time','Class'],axis=1)\n",
    "# Normalize Amount\n",
    "df_features[\"Amount\"]=(df_features[\"Amount\"]-df_features[\"Amount\"].mean())/df_features[\"Amount\"].std()\n",
    "# Create train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_features,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear classifier in tensorflow\n",
    "nV01 = tf.feature_column.numeric_column('V1')\n",
    "nV02 = tf.feature_column.numeric_column('V2')\n",
    "nV03 = tf.feature_column.numeric_column('V3')\n",
    "nV04 = tf.feature_column.numeric_column('V4')\n",
    "nV05 = tf.feature_column.numeric_column('V5')\n",
    "nV06 = tf.feature_column.numeric_column('V6')\n",
    "nV07 = tf.feature_column.numeric_column('V7')\n",
    "nV09 = tf.feature_column.numeric_column('V9')\n",
    "nV10 = tf.feature_column.numeric_column('V10')\n",
    "nV11 = tf.feature_column.numeric_column('V11')\n",
    "nV12 = tf.feature_column.numeric_column('V12')\n",
    "nV14 = tf.feature_column.numeric_column('V14')\n",
    "nV16 = tf.feature_column.numeric_column('V16')\n",
    "nV17 = tf.feature_column.numeric_column('V17')\n",
    "nV18 = tf.feature_column.numeric_column('V18')\n",
    "nV19 = tf.feature_column.numeric_column('V19')\n",
    "nV21 = tf.feature_column.numeric_column('V21')\n",
    "nV22 = tf.feature_column.numeric_column('V22')\n",
    "nV30 = tf.feature_column.numeric_column('Amount')\n",
    "\n",
    "features=[nV01,nV02,nV03,nV04,nV05,nV06,nV07,nV09,nV10,nV11,nV12,nV14,nV16,nV17,nV18,nV19,nV21,nV30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmp5p2pvdwj\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\MANISA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp5p2pvdwj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002019FE65940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmp5p2pvdwj\\model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31474, step = 1\n",
      "INFO:tensorflow:global_step/sec: 86.3631\n",
      "INFO:tensorflow:loss = 9.454085, step = 101 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.326\n",
      "INFO:tensorflow:loss = 4.5581894, step = 201 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.314\n",
      "INFO:tensorflow:loss = 3.216841, step = 301 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.227\n",
      "INFO:tensorflow:loss = 6.0582824, step = 401 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.847\n",
      "INFO:tensorflow:loss = 1.9733648, step = 501 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.444\n",
      "INFO:tensorflow:loss = 3.4795094, step = 601 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.406\n",
      "INFO:tensorflow:loss = 1.4452746, step = 701 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.155\n",
      "INFO:tensorflow:loss = 1.2681537, step = 801 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.986\n",
      "INFO:tensorflow:loss = 1.1433661, step = 901 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.945\n",
      "INFO:tensorflow:loss = 1.0904896, step = 1001 (0.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.151\n",
      "INFO:tensorflow:loss = 0.9689098, step = 1101 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.804\n",
      "INFO:tensorflow:loss = 0.8390344, step = 1201 (0.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.726\n",
      "INFO:tensorflow:loss = 0.8076238, step = 1301 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.765\n",
      "INFO:tensorflow:loss = 0.75699043, step = 1401 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.549\n",
      "INFO:tensorflow:loss = 0.7248777, step = 1501 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.424\n",
      "INFO:tensorflow:loss = 0.65954864, step = 1601 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.428\n",
      "INFO:tensorflow:loss = 0.62004304, step = 1701 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.401\n",
      "INFO:tensorflow:loss = 0.5844711, step = 1801 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.669\n",
      "INFO:tensorflow:loss = 0.54775023, step = 1901 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.462\n",
      "INFO:tensorflow:loss = 0.562531, step = 2001 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.08\n",
      "INFO:tensorflow:loss = 0.53324926, step = 2101 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.401\n",
      "INFO:tensorflow:loss = 4.8109884, step = 2201 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.005\n",
      "INFO:tensorflow:loss = 0.5428221, step = 2301 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.444\n",
      "INFO:tensorflow:loss = 0.45394617, step = 2401 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.738\n",
      "INFO:tensorflow:loss = 0.4494612, step = 2501 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.373\n",
      "INFO:tensorflow:loss = 0.42873082, step = 2601 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.048\n",
      "INFO:tensorflow:loss = 0.4659663, step = 2701 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.236\n",
      "INFO:tensorflow:loss = 0.52587855, step = 2801 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.43\n",
      "INFO:tensorflow:loss = 0.40409535, step = 2901 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.92\n",
      "INFO:tensorflow:loss = 0.45379224, step = 3001 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.18\n",
      "INFO:tensorflow:loss = 0.3820961, step = 3101 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.021\n",
      "INFO:tensorflow:loss = 6.1646605, step = 3201 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.208\n",
      "INFO:tensorflow:loss = 0.36046863, step = 3301 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.921\n",
      "INFO:tensorflow:loss = 0.34859204, step = 3401 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.805\n",
      "INFO:tensorflow:loss = 0.31256524, step = 3501 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.258\n",
      "INFO:tensorflow:loss = 0.3391112, step = 3601 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.236\n",
      "INFO:tensorflow:loss = 0.30267859, step = 3701 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.401\n",
      "INFO:tensorflow:loss = 1.064012, step = 3801 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.159\n",
      "INFO:tensorflow:loss = 0.28754684, step = 3901 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.66\n",
      "INFO:tensorflow:loss = 3.0145106, step = 4001 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.425\n",
      "INFO:tensorflow:loss = 0.271267, step = 4101 (0.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.239\n",
      "INFO:tensorflow:loss = 4.840592, step = 4201 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.821\n",
      "INFO:tensorflow:loss = 0.2920199, step = 4301 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.691\n",
      "INFO:tensorflow:loss = 0.2638195, step = 4401 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.43\n",
      "INFO:tensorflow:loss = 0.24878807, step = 4501 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.847\n",
      "INFO:tensorflow:loss = 0.35643545, step = 4601 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.978\n",
      "INFO:tensorflow:loss = 0.28345287, step = 4701 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.258\n",
      "INFO:tensorflow:loss = 0.45429826, step = 4801 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.156\n",
      "INFO:tensorflow:loss = 0.24172696, step = 4901 (0.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.236\n",
      "INFO:tensorflow:loss = 0.24636967, step = 5001 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.235\n",
      "INFO:tensorflow:loss = 0.22640471, step = 5101 (0.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.887\n",
      "INFO:tensorflow:loss = 0.22447151, step = 5201 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.765\n",
      "INFO:tensorflow:loss = 0.24144645, step = 5301 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.445\n",
      "INFO:tensorflow:loss = 0.23183373, step = 5401 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.408\n",
      "INFO:tensorflow:loss = 0.22010812, step = 5501 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.427\n",
      "INFO:tensorflow:loss = 0.23222269, step = 5601 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.12\n",
      "INFO:tensorflow:loss = 0.21253955, step = 5701 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.514\n",
      "INFO:tensorflow:loss = 0.21462488, step = 5801 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8403\n",
      "INFO:tensorflow:loss = 1.9007126, step = 5901 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.915\n",
      "INFO:tensorflow:loss = 0.31880283, step = 6001 (0.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.279\n",
      "INFO:tensorflow:loss = 0.18696879, step = 6101 (0.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.46\n",
      "INFO:tensorflow:loss = 0.25281978, step = 6201 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.235\n",
      "INFO:tensorflow:loss = 0.35644796, step = 6301 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.454\n",
      "INFO:tensorflow:loss = 5.580329, step = 6401 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.6885\n",
      "INFO:tensorflow:loss = 0.17451778, step = 6501 (1.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.0069\n",
      "INFO:tensorflow:loss = 0.1829885, step = 6601 (1.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.262\n",
      "INFO:tensorflow:loss = 0.17897007, step = 6701 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.877\n",
      "INFO:tensorflow:loss = 0.19751468, step = 6801 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.887\n",
      "INFO:tensorflow:loss = 0.15338266, step = 6901 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.02\n",
      "INFO:tensorflow:loss = 0.1718963, step = 7001 (0.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1954432, step = 7101 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.986\n",
      "INFO:tensorflow:loss = 0.17156684, step = 7201 (0.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.534\n",
      "INFO:tensorflow:loss = 0.17690164, step = 7301 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.6\n",
      "INFO:tensorflow:loss = 0.83255196, step = 7401 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.11\n",
      "INFO:tensorflow:loss = 0.1720853, step = 7501 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.478\n",
      "INFO:tensorflow:loss = 0.1758926, step = 7601 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.047\n",
      "INFO:tensorflow:loss = 0.15488529, step = 7701 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.768\n",
      "INFO:tensorflow:loss = 0.14817545, step = 7801 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.811\n",
      "INFO:tensorflow:loss = 0.19919932, step = 7901 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.552\n",
      "INFO:tensorflow:loss = 0.18240109, step = 8001 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.869\n",
      "INFO:tensorflow:loss = 0.15501413, step = 8101 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.874\n",
      "INFO:tensorflow:loss = 0.18499151, step = 8201 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.978\n",
      "INFO:tensorflow:loss = 0.16866046, step = 8301 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.831\n",
      "INFO:tensorflow:loss = 0.16439518, step = 8401 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.421\n",
      "INFO:tensorflow:loss = 0.1798099, step = 8501 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.621\n",
      "INFO:tensorflow:loss = 0.1699208, step = 8601 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.131\n",
      "INFO:tensorflow:loss = 0.1597418, step = 8701 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.105\n",
      "INFO:tensorflow:loss = 0.15984827, step = 8801 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.4\n",
      "INFO:tensorflow:loss = 0.15697569, step = 8901 (0.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.818\n",
      "INFO:tensorflow:loss = 0.7000896, step = 9001 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.549\n",
      "INFO:tensorflow:loss = 0.17759761, step = 9101 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.556\n",
      "INFO:tensorflow:loss = 0.14409971, step = 9201 (0.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.549\n",
      "INFO:tensorflow:loss = 0.5323963, step = 9301 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.59\n",
      "INFO:tensorflow:loss = 0.15654641, step = 9401 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.3\n",
      "INFO:tensorflow:loss = 0.15560846, step = 9501 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.4112\n",
      "INFO:tensorflow:loss = 0.13127233, step = 9601 (1.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.376\n",
      "INFO:tensorflow:loss = 0.1462073, step = 9701 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.27\n",
      "INFO:tensorflow:loss = 0.14352368, step = 9801 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.73\n",
      "INFO:tensorflow:loss = 0.14479037, step = 9901 (0.727 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmp5p2pvdwj\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.14031115.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-02-01:52:10\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmp5p2pvdwj\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-02-01:53:58\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.999047, accuracy_baseline = 0.9981491, auc = 0.93616277, auc_precision_recall = 0.73481107, average_loss = 0.0050292276, global_step = 10000, label/mean = 0.0018508858, loss = 0.05029076, precision = 0.8808511, prediction/mean = 0.0026674229, recall = 0.5609756\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmp5p2pvdwj\\model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow: Linear Classifier\n",
    "input_func=tf.estimator.inputs.pandas_input_fn(x=x_train,y=y_train,batch_size=100,num_epochs=1000,shuffle=True) \n",
    "model=tf.estimator.LinearClassifier(feature_columns=features,n_classes=2)\n",
    "model.train(input_fn=input_func,steps=10000)\n",
    "result1=model.evaluate(tf.estimator.inputs.pandas_input_fn(x=x_train,y=y_train,batch_size=10, num_epochs=1, shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999047\n"
     ]
    }
   ],
   "source": [
    "print(result1['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-01-23:22:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmpz7v00kry\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-01-23:23:42\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.99947333, accuracy_baseline = 0.9985604, auc = 0.9840646, auc_precision_recall = 0.78030455, average_loss = 0.012920172, global_step = 1000, label/mean = 0.0014395562, loss = 0.12919113, precision = 0.84210527, prediction/mean = 0.01148642, recall = 0.7804878\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmpz7v00kry\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "# Test Linear classification\n",
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x=x_test,y=y_test,batch_size=10, num_epochs=1, shuffle=False)\n",
    "results2=model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99947333\n"
     ]
    }
   ],
   "source": [
    "print(results2['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MANISA~1\\AppData\\Local\\Temp\\tmpz7v00kry\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20196deabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction:\n",
    "from sklearn import metrics\n",
    "pred_input_func= tf.estimator.inputs.pandas_input_fn(x=x_test,batch_size=10,num_epochs=1,shuffle=False)\n",
    "predictions = model.predict(pred_input_func)\n",
    "\n",
    "y_pred=[d['logits'] for d in predictions]\n",
    "fpr,tpr,thresholds=metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc=metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('ROC-Tensorflow')\n",
    "plt.plot(fpr, tpr,'b', label='Area under curve = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network: use all the attributes\n",
    "x_neural=df.drop(['Class'],axis=1)\n",
    "x_scaled_neural=(x_neural-x_neural.min())/(x_neural.max()-x_neural.min())\n",
    "y_neural=df.Class\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_neural,x_test_neural,y_train_neural,y_test_neural=train_test_split(x_scaled_neural,y_neural,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed data into the network\n",
    "def to_one_hot(c, depth):\n",
    "    i=np.identity(depth)\n",
    "    return i[c,:]\n",
    "\n",
    "def train_batch(batch_size):\n",
    "    for j in range(int(len(x_train_neural)/batch_size)):\n",
    "        start=batch_size*j\n",
    "        end=start+batch_size\n",
    "        \n",
    "        train_x_batch=x_train_neural[start:end]\n",
    "        train_y_batch=y_train_neural[start:end]\n",
    "        \n",
    "        train_y_batch=np.apply_along_axis(lambda x:to_one_hot(x,depth=2),0,train_y_batch)\n",
    "        \n",
    "        yield train_x_batch, train_y_batch\n",
    "        \n",
    "def get_test_data():\n",
    "    return x_test_neural, np.apply_along_axis(lambda x: to_one_hot(x, depth=2), 0, y_test_neural)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 1114.3825511336327\n",
      "Epoch 2 loss: 1079.2306271195412\n",
      "Epoch 3 loss: 1079.2306271195412\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "X= tf.placeholder(tf.float32, [None, 30]) # inputs\n",
    "Y= tf.placeholder(tf.float32, [None, 2]) # targets\n",
    "\n",
    "def forward_propogation(X): # model\n",
    "    num_neural= 10\n",
    "    weights={\"lvl_1\": tf.Variable(tf.random_normal([30,num_neural])), \n",
    "               \"output\": tf.Variable(tf.random_normal([num_neural,2]))}\n",
    "    \n",
    "    biases={\"lvl_1\": tf.Variable(tf.random_normal([num_neural])), \n",
    "            \"output\": tf.Variable(tf.random_normal([2]))}\n",
    "    \n",
    "    h1=tf.add(tf.matmul(X, weights[\"lvl_1\"]), biases[\"lvl_1\"])\n",
    "    h1=tf.nn.relu(h1)\n",
    "    \n",
    "    h2=tf.add(tf.matmul(h1, weights[\"output\"]), biases[\"output\"])\n",
    "    output=tf.nn.relu(h2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Minimize loss\n",
    "logits=forward_propogation(X)\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "optimizer=tf.train.AdamOptimizer(0.01).minimize(loss) \n",
    "\n",
    "# Confusion matrix accuracy\n",
    "correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) \n",
    "\n",
    "# Precision-recall curve\n",
    "decision_variable = tf.nn.softmax(logits) \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train phase\n",
    "    batch_size = 128\n",
    "    n_epochs = 3\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        batch_generator = train_batch(batch_size)\n",
    "        for batch in batch_generator:\n",
    "            batch_x, batch_t = batch \n",
    "            _, curr_loss = sess.run([optimizer, loss], feed_dict={Y: batch_t, X: batch_x})\n",
    "            epoch_loss += curr_loss\n",
    "            \n",
    "        print(\"Epoch \" + str(epoch+1) + \" loss: \" + str(epoch_loss))\n",
    "        \n",
    "    # test phase\n",
    "    test_x, test_t = get_test_data()\n",
    "    test_y = sess.run(decision_variable, feed_dict={X: test_x})\n",
    "    \n",
    "    auprc = average_precision_score(test_t[:,0], test_y[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984082955888721\n"
     ]
    }
   ],
   "source": [
    "    print(auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
